{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15], Step [50/469], Reconst_Loss:25947.347656, KL_Loss:691.180542\n",
      "Epoch [1/15], Step [100/469], Reconst_Loss:22439.857422, KL_Loss:1356.777466\n",
      "Epoch [1/15], Step [150/469], Reconst_Loss:19759.914062, KL_Loss:1666.079468\n",
      "Epoch [1/15], Step [200/469], Reconst_Loss:17545.867188, KL_Loss:1925.825684\n",
      "Epoch [1/15], Step [250/469], Reconst_Loss:16550.214844, KL_Loss:2077.678223\n",
      "Epoch [1/15], Step [300/469], Reconst_Loss:15376.714844, KL_Loss:2229.704834\n",
      "Epoch [1/15], Step [350/469], Reconst_Loss:14987.294922, KL_Loss:2473.872559\n",
      "Epoch [1/15], Step [400/469], Reconst_Loss:13991.927734, KL_Loss:2422.817383\n",
      "Epoch [1/15], Step [450/469], Reconst_Loss:14105.095703, KL_Loss:2578.634521\n",
      "Epoch [2/15], Step [50/469], Reconst_Loss:13983.945312, KL_Loss:2769.368896\n",
      "Epoch [2/15], Step [100/469], Reconst_Loss:12767.343750, KL_Loss:2848.732910\n",
      "Epoch [2/15], Step [150/469], Reconst_Loss:13396.431641, KL_Loss:2685.715332\n",
      "Epoch [2/15], Step [200/469], Reconst_Loss:12947.308594, KL_Loss:2851.184570\n",
      "Epoch [2/15], Step [250/469], Reconst_Loss:12559.292969, KL_Loss:2840.379883\n",
      "Epoch [2/15], Step [300/469], Reconst_Loss:12200.291016, KL_Loss:2850.725830\n",
      "Epoch [2/15], Step [350/469], Reconst_Loss:12210.728516, KL_Loss:2824.078857\n",
      "Epoch [2/15], Step [400/469], Reconst_Loss:12012.391602, KL_Loss:2866.269775\n",
      "Epoch [2/15], Step [450/469], Reconst_Loss:12247.929688, KL_Loss:2860.591797\n",
      "Epoch [3/15], Step [50/469], Reconst_Loss:11561.921875, KL_Loss:3013.743652\n",
      "Epoch [3/15], Step [100/469], Reconst_Loss:12056.910156, KL_Loss:2993.492188\n",
      "Epoch [3/15], Step [150/469], Reconst_Loss:11372.510742, KL_Loss:3097.041504\n",
      "Epoch [3/15], Step [200/469], Reconst_Loss:11800.479492, KL_Loss:3086.385498\n",
      "Epoch [3/15], Step [250/469], Reconst_Loss:11516.600586, KL_Loss:2925.366943\n",
      "Epoch [3/15], Step [300/469], Reconst_Loss:12023.234375, KL_Loss:3011.491699\n",
      "Epoch [3/15], Step [350/469], Reconst_Loss:11486.142578, KL_Loss:2958.270996\n",
      "Epoch [3/15], Step [400/469], Reconst_Loss:11323.317383, KL_Loss:3103.456543\n",
      "Epoch [3/15], Step [450/469], Reconst_Loss:11257.105469, KL_Loss:3000.996094\n",
      "Epoch [4/15], Step [50/469], Reconst_Loss:11243.758789, KL_Loss:3045.501465\n",
      "Epoch [4/15], Step [100/469], Reconst_Loss:11311.260742, KL_Loss:3073.283447\n",
      "Epoch [4/15], Step [150/469], Reconst_Loss:11025.516602, KL_Loss:3140.947021\n",
      "Epoch [4/15], Step [200/469], Reconst_Loss:11249.261719, KL_Loss:3210.163086\n",
      "Epoch [4/15], Step [250/469], Reconst_Loss:11216.332031, KL_Loss:3123.267090\n",
      "Epoch [4/15], Step [300/469], Reconst_Loss:11275.891602, KL_Loss:3144.972168\n",
      "Epoch [4/15], Step [350/469], Reconst_Loss:10978.686523, KL_Loss:3171.161133\n",
      "Epoch [4/15], Step [400/469], Reconst_Loss:11055.296875, KL_Loss:3097.472900\n",
      "Epoch [4/15], Step [450/469], Reconst_Loss:10417.484375, KL_Loss:3097.744629\n",
      "Epoch [5/15], Step [50/469], Reconst_Loss:11048.082031, KL_Loss:3193.823486\n",
      "Epoch [5/15], Step [100/469], Reconst_Loss:11193.081055, KL_Loss:3105.197754\n",
      "Epoch [5/15], Step [150/469], Reconst_Loss:10413.984375, KL_Loss:3077.082520\n",
      "Epoch [5/15], Step [200/469], Reconst_Loss:10447.253906, KL_Loss:3186.544189\n",
      "Epoch [5/15], Step [250/469], Reconst_Loss:10604.176758, KL_Loss:3151.297852\n",
      "Epoch [5/15], Step [300/469], Reconst_Loss:10760.261719, KL_Loss:3182.472168\n",
      "Epoch [5/15], Step [350/469], Reconst_Loss:10810.906250, KL_Loss:3255.222412\n",
      "Epoch [5/15], Step [400/469], Reconst_Loss:10867.505859, KL_Loss:3138.819824\n",
      "Epoch [5/15], Step [450/469], Reconst_Loss:10813.384766, KL_Loss:3124.377686\n",
      "Epoch [6/15], Step [50/469], Reconst_Loss:11045.604492, KL_Loss:3080.766846\n",
      "Epoch [6/15], Step [100/469], Reconst_Loss:10759.084961, KL_Loss:3133.208008\n",
      "Epoch [6/15], Step [150/469], Reconst_Loss:10601.684570, KL_Loss:3200.291992\n",
      "Epoch [6/15], Step [200/469], Reconst_Loss:10742.503906, KL_Loss:3137.809326\n",
      "Epoch [6/15], Step [250/469], Reconst_Loss:10950.742188, KL_Loss:3202.982422\n",
      "Epoch [6/15], Step [300/469], Reconst_Loss:11012.690430, KL_Loss:3171.447754\n",
      "Epoch [6/15], Step [350/469], Reconst_Loss:10877.877930, KL_Loss:3148.235352\n",
      "Epoch [6/15], Step [400/469], Reconst_Loss:10431.515625, KL_Loss:3123.144531\n",
      "Epoch [6/15], Step [450/469], Reconst_Loss:10539.728516, KL_Loss:3185.068115\n",
      "Epoch [7/15], Step [50/469], Reconst_Loss:11036.214844, KL_Loss:3071.749023\n",
      "Epoch [7/15], Step [100/469], Reconst_Loss:10529.977539, KL_Loss:3171.243408\n",
      "Epoch [7/15], Step [150/469], Reconst_Loss:10406.352539, KL_Loss:3136.015625\n",
      "Epoch [7/15], Step [200/469], Reconst_Loss:11146.182617, KL_Loss:3162.332764\n",
      "Epoch [7/15], Step [250/469], Reconst_Loss:10767.313477, KL_Loss:3212.562012\n",
      "Epoch [7/15], Step [300/469], Reconst_Loss:10664.994141, KL_Loss:3258.432373\n",
      "Epoch [7/15], Step [350/469], Reconst_Loss:10628.940430, KL_Loss:3134.894531\n",
      "Epoch [7/15], Step [400/469], Reconst_Loss:10715.126953, KL_Loss:3202.906738\n",
      "Epoch [7/15], Step [450/469], Reconst_Loss:10852.567383, KL_Loss:3220.051758\n",
      "Epoch [8/15], Step [50/469], Reconst_Loss:10772.061523, KL_Loss:3221.650391\n",
      "Epoch [8/15], Step [100/469], Reconst_Loss:10345.495117, KL_Loss:3200.129639\n",
      "Epoch [8/15], Step [150/469], Reconst_Loss:10371.066406, KL_Loss:3222.563965\n",
      "Epoch [8/15], Step [200/469], Reconst_Loss:10795.230469, KL_Loss:3186.416748\n",
      "Epoch [8/15], Step [250/469], Reconst_Loss:10486.882812, KL_Loss:3128.747070\n",
      "Epoch [8/15], Step [300/469], Reconst_Loss:10506.445312, KL_Loss:3236.267578\n",
      "Epoch [8/15], Step [350/469], Reconst_Loss:10348.229492, KL_Loss:3221.089844\n",
      "Epoch [8/15], Step [400/469], Reconst_Loss:10703.500000, KL_Loss:3282.415771\n",
      "Epoch [8/15], Step [450/469], Reconst_Loss:10427.284180, KL_Loss:3151.817139\n",
      "Epoch [9/15], Step [50/469], Reconst_Loss:10617.949219, KL_Loss:3256.645020\n",
      "Epoch [9/15], Step [100/469], Reconst_Loss:10396.111328, KL_Loss:3270.234863\n",
      "Epoch [9/15], Step [150/469], Reconst_Loss:10502.136719, KL_Loss:3105.734131\n",
      "Epoch [9/15], Step [200/469], Reconst_Loss:10137.583984, KL_Loss:3212.744629\n",
      "Epoch [9/15], Step [250/469], Reconst_Loss:9790.107422, KL_Loss:3146.280762\n",
      "Epoch [9/15], Step [300/469], Reconst_Loss:10182.751953, KL_Loss:3100.246582\n",
      "Epoch [9/15], Step [350/469], Reconst_Loss:10403.079102, KL_Loss:3120.388428\n",
      "Epoch [9/15], Step [400/469], Reconst_Loss:10530.448242, KL_Loss:3362.180664\n",
      "Epoch [9/15], Step [450/469], Reconst_Loss:10360.651367, KL_Loss:3190.184814\n",
      "Epoch [10/15], Step [50/469], Reconst_Loss:10453.242188, KL_Loss:3307.479492\n",
      "Epoch [10/15], Step [100/469], Reconst_Loss:10770.115234, KL_Loss:3257.216064\n",
      "Epoch [10/15], Step [150/469], Reconst_Loss:10313.543945, KL_Loss:3219.027588\n",
      "Epoch [10/15], Step [200/469], Reconst_Loss:10584.875977, KL_Loss:3112.096680\n",
      "Epoch [10/15], Step [250/469], Reconst_Loss:10780.177734, KL_Loss:3227.282715\n",
      "Epoch [10/15], Step [300/469], Reconst_Loss:10137.368164, KL_Loss:3187.392334\n",
      "Epoch [10/15], Step [350/469], Reconst_Loss:10548.333984, KL_Loss:3217.293457\n",
      "Epoch [10/15], Step [400/469], Reconst_Loss:10745.062500, KL_Loss:3276.106201\n",
      "Epoch [10/15], Step [450/469], Reconst_Loss:10371.573242, KL_Loss:3183.044434\n",
      "Epoch [11/15], Step [50/469], Reconst_Loss:10191.496094, KL_Loss:3160.215820\n",
      "Epoch [11/15], Step [100/469], Reconst_Loss:10561.872070, KL_Loss:3213.635986\n",
      "Epoch [11/15], Step [150/469], Reconst_Loss:10099.329102, KL_Loss:3136.112793\n",
      "Epoch [11/15], Step [200/469], Reconst_Loss:10120.789062, KL_Loss:3091.411377\n",
      "Epoch [11/15], Step [250/469], Reconst_Loss:10201.748047, KL_Loss:3199.423340\n",
      "Epoch [11/15], Step [300/469], Reconst_Loss:10442.627930, KL_Loss:3188.623047\n",
      "Epoch [11/15], Step [350/469], Reconst_Loss:10198.125977, KL_Loss:3238.979004\n",
      "Epoch [11/15], Step [400/469], Reconst_Loss:10548.935547, KL_Loss:3232.780273\n",
      "Epoch [11/15], Step [450/469], Reconst_Loss:10384.151367, KL_Loss:3256.166992\n",
      "Epoch [12/15], Step [50/469], Reconst_Loss:10027.179688, KL_Loss:3208.722168\n",
      "Epoch [12/15], Step [100/469], Reconst_Loss:10113.004883, KL_Loss:3239.274414\n",
      "Epoch [12/15], Step [150/469], Reconst_Loss:9674.428711, KL_Loss:3151.407227\n",
      "Epoch [12/15], Step [200/469], Reconst_Loss:10023.866211, KL_Loss:3155.025391\n",
      "Epoch [12/15], Step [250/469], Reconst_Loss:10321.361328, KL_Loss:3245.671387\n",
      "Epoch [12/15], Step [300/469], Reconst_Loss:10626.979492, KL_Loss:3335.613037\n",
      "Epoch [12/15], Step [350/469], Reconst_Loss:10336.585938, KL_Loss:3317.519775\n",
      "Epoch [12/15], Step [400/469], Reconst_Loss:10233.285156, KL_Loss:3275.882568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/15], Step [450/469], Reconst_Loss:10552.708008, KL_Loss:3283.437256\n",
      "Epoch [13/15], Step [50/469], Reconst_Loss:10284.891602, KL_Loss:3266.072021\n",
      "Epoch [13/15], Step [100/469], Reconst_Loss:10099.204102, KL_Loss:3211.196289\n",
      "Epoch [13/15], Step [150/469], Reconst_Loss:9912.716797, KL_Loss:3221.292969\n",
      "Epoch [13/15], Step [200/469], Reconst_Loss:10227.446289, KL_Loss:3265.600098\n",
      "Epoch [13/15], Step [250/469], Reconst_Loss:10473.505859, KL_Loss:3086.606201\n",
      "Epoch [13/15], Step [300/469], Reconst_Loss:9736.595703, KL_Loss:3141.135986\n",
      "Epoch [13/15], Step [350/469], Reconst_Loss:10320.042969, KL_Loss:3175.619629\n",
      "Epoch [13/15], Step [400/469], Reconst_Loss:10043.908203, KL_Loss:3169.038330\n",
      "Epoch [13/15], Step [450/469], Reconst_Loss:10309.806641, KL_Loss:3183.256348\n",
      "Epoch [14/15], Step [50/469], Reconst_Loss:9946.529297, KL_Loss:3295.073242\n",
      "Epoch [14/15], Step [100/469], Reconst_Loss:10300.095703, KL_Loss:3260.750000\n",
      "Epoch [14/15], Step [150/469], Reconst_Loss:10187.924805, KL_Loss:3276.317139\n",
      "Epoch [14/15], Step [200/469], Reconst_Loss:10033.644531, KL_Loss:3227.906250\n",
      "Epoch [14/15], Step [250/469], Reconst_Loss:10576.503906, KL_Loss:3211.196777\n",
      "Epoch [14/15], Step [300/469], Reconst_Loss:9903.708984, KL_Loss:3123.379883\n",
      "Epoch [14/15], Step [350/469], Reconst_Loss:10624.141602, KL_Loss:3328.150391\n",
      "Epoch [14/15], Step [400/469], Reconst_Loss:10154.289062, KL_Loss:3173.261475\n",
      "Epoch [14/15], Step [450/469], Reconst_Loss:10381.516602, KL_Loss:3236.699219\n",
      "Epoch [15/15], Step [50/469], Reconst_Loss:9539.346680, KL_Loss:3121.211914\n",
      "Epoch [15/15], Step [100/469], Reconst_Loss:9815.630859, KL_Loss:3372.373291\n",
      "Epoch [15/15], Step [150/469], Reconst_Loss:9885.475586, KL_Loss:3235.704346\n",
      "Epoch [15/15], Step [200/469], Reconst_Loss:9896.934570, KL_Loss:3107.661621\n",
      "Epoch [15/15], Step [250/469], Reconst_Loss:10359.327148, KL_Loss:3261.802002\n",
      "Epoch [15/15], Step [300/469], Reconst_Loss:10405.529297, KL_Loss:3339.292969\n",
      "Epoch [15/15], Step [350/469], Reconst_Loss:10154.310547, KL_Loss:3230.635010\n",
      "Epoch [15/15], Step [400/469], Reconst_Loss:9937.910156, KL_Loss:3174.796387\n",
      "Epoch [15/15], Step [450/469], Reconst_Loss:9893.018555, KL_Loss:3233.842773\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision.transforms import transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Create a directory\n",
    "sample_dir = 'samples'\n",
    "if not os.path.exists(sample_dir):\n",
    "    os.makedirs(sample_dir)\n",
    "    \n",
    "# Hyperparameters\n",
    "image_size = 784\n",
    "h_dim = 400\n",
    "z_dim = 20\n",
    "num_epochs = 15\n",
    "batch_size = 128\n",
    "learning_rate = 1e-3\n",
    "\n",
    "# MNIST dataset\n",
    "dataset = torchvision.datasets.MNIST(root='../../data', train=True, transform = transforms.ToTensor(), download = True)\n",
    "\n",
    "# Data Loader \n",
    "dataloader = torch.utils.data.DataLoader(dataset = dataset, batch_size = batch_size, shuffle=True)\n",
    "\n",
    "# VAE model\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, image_size=784, h_dim=400, z_dim=20):\n",
    "        super(VAE, self).__init__()\n",
    "        self.fc1 = nn.Linear(image_size, h_dim)\n",
    "        self.fc2 = nn.Linear(h_dim, z_dim)\n",
    "        self.fc3 = nn.Linear(h_dim, z_dim)\n",
    "        self.fc4 = nn.Linear(z_dim, h_dim)\n",
    "        self.fc5 = nn.Linear(h_dim, image_size)\n",
    "        \n",
    "    def encode(self, x):\n",
    "        h = F.relu(self.fc1(x))\n",
    "        return self.fc2(h), self.fc3(h)\n",
    "    \n",
    "    def reparameterize(self, mu, log_var):\n",
    "        std = torch.exp(log_var/2)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "    \n",
    "    def decode(self, z):\n",
    "        h = F.relu(self.fc4(z))\n",
    "        return F.sigmoid(self.fc5(h))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu, log_var = self.encode(x)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        x_reconst = self.decode(z)\n",
    "        return x_reconst, mu, log_var\n",
    "    \n",
    "model = VAE().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Start Training\n",
    "for epoch in range(num_epochs):\n",
    "    for i,(x, _) in enumerate(dataloader):\n",
    "        # Forward pass\n",
    "        x = x.to(device).view(-1, image_size)\n",
    "        x_reconst, mu, log_var = model(x)\n",
    "        \n",
    "        # Compute the reconstruction loss and kl divergence\n",
    "        reconst_loss = F.binary_cross_entropy(x_reconst, x, size_average=False)\n",
    "        kl_div = -0.5*torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "        \n",
    "        # Backprop and optimize\n",
    "        loss = reconst_loss + kl_div\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 50 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Reconst_Loss:{:4f}, KL_Loss:{:4f}'.\n",
    "                  format(epoch+1, num_epochs, i+1,len(dataloader),reconst_loss.item(), kl_div.item()))\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        # Save the sampled images\n",
    "        z = torch.randn(batch_size, z_dim).to(device)\n",
    "        out = model.decode(z).view(-1, 1, 28, 28)\n",
    "        save_image(out, os.path.join(sample_dir, 'sampled-{}.png'.format(epoch+1)))\n",
    "        \n",
    "        # Save the reconstructed image\n",
    "        out, _, _ = model(x)\n",
    "        x_concat = torch.cat([x.view(-1, 1, 28, 28), out.view(-1, 1, 28, 28)], dim = 3)\n",
    "        save_image(x_concat, os.path.join(sample_dir, 'reconst-{}.jpg'.format(epoch+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
